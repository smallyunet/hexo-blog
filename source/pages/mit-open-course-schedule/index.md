---
title: MIT Open Course Schedule
date: 2021-01-11 22:33:08
---

### 更新

已经连续很多天 “没有” 时间看课程视频了。回过头看，其实从课程视频中获得的信息是十分有限的，现在已经进入了和预期一致的、开始看就会走神的状态，简直和真实的上课状态一模一样。

从一开始的目的来说，我是希望可以通过 “正统” 的视频课程，系统地了解某一门课程的内容，以不至于落后于还在深入学业的同学。但其实，至少对我来说，真正有用的东西大多不是从学校或者课堂学到的。我应该学会不再在乎这样的比较。

有很多不同领域的、有趣的、有价值的视频和内容，都值得被关注。当时间从一开始可以随意浪费，到把时间用来看美剧，到只能把时间用来看课程视频，到连续 1 小时的视频课程视频都没有耐心看完……

开始于 01.11，结束于 05.15。时间有点短了，原准备连续 3 年的。（为什么是 3 年呢 :P

### 说明

我计划把一些公开课作为学习渠道、有规律地看完，就像列一个课程表一样，而不像其他内容仅仅是消遣，随心所欲地想哪儿就哪儿。我也不知道能坚持多长时间，可能是一天，也可能是一年。因为没有课后作业和考试，时间充足的情况下，应该不会有压力。当然，课程内容不会局限于计算机科学领域。

由于现实环境的不可预测性质，课程表不能规定的太严格，但是公开课又太多了，必须保证足够的进度。初步规则为：

- 按照 <i>课程数 * 1.5</i> 的方式规划每一门课的结束时间
- 如果在规定时间内没有完成，就需要在接下来的时间里、下一门课正常进行的情况下，补完上一门课
- 一门课程结束后，需要在接下来 3 天内选出下一门课
- 不跳过节假日
- 存在两门以上课程同时进行的情况
- 在一门课进行的情况下，如果另一门课结束，不需要补充下一门课。只需要保证至少有一门课在进行

关于多门课同时进行的发现（[图](./2021.02.02.png)）：

- 最多同时两门课，否则时间来不及
- 按照 1.5 倍时间的估算，两门课交替一天一次，周末两次，时间刚好没有空挡
- 确实存在两门以上课程同时进行的情况，时间上不好管理了，只能适当放宽结束时间
- （04.15）时间彻底乱了（狗头）

### 课程表

1

|Title|Intrduction to Computer Science and Programming in Python|
|:-|:-|
|**No.**|**6.0001, Fall 2016**|
|**Date**|**2021.01.11 ~ 2021.01.29 （12 lectures）**|
|||
|Lecture 1|What is Computation? <sdr>01.11</sdr>|
|Lecture 2|Branching and Iteration <sdr>01.12</sdr>|
|Lecture 3|String Manipulation, Guess and Check, Approximations, Bisection <sdr>01.13</sdr>|
|Lecture 4|Decomposition, Abstraction, and Function <sdr>01.14</sdr>|
|Lecture 5|Tuples, Lists, Aliasing, Mutability, and Cloning <sdr>01.16</sdr>|
|Lecture 6|Recursion and Dictionaries <sdr>01.17</sdr>|
|Lecture 7|Testing, Debugging, Exceptions, and Assertions <sdr>01.20</sdr>|
|Lecture 8|Ojbect Oriented Programming <sdr>01.23</sdr>|
|Lecture 9|Python Classes and Inheritance <sdr>01.23</sdr>|
|Lecture 10|Understanding Program Efficiency, Part 1 <sdr>01.24</sdr>|
|Lecture 11|Understanding Program Efficiency, Part 2 <sdr>01.26</sdr>|
|Lecture 12|Searching and Sorting <sdr>01.29</sdr>|

2 (2.1)

|Title|Intrduction to Computational Thinking and Data Science|
|:-|:-|
|**No.**|**6.0002, Fall 2016**|
|**Date**|**2021.01.30 ~ 2021.02.23 （15 lectures）**|
|||
|Lecture 1|Introduction, Optimization Problems <sdr>01.30</sdr>|
|Lecture 2|Optimization Problems <sdr>01.31</sdr>|
|Lecture 3|Graph-theoretic Models <sdr>02.01</sdr>|
|Lecture 4|Stochastic Thinking <sdr>02.03</sdr>|
|Lecture 5|Random Walks <sdr>02.05</sdr>|
|Lecture 6|Monte Carlo Simulation <sdr>02.06</sdr>|
|Lecture 7|Confidence Intervals <sdr>02.07</sdr>|
|Lecture 8|Sampling and Standard Error <sdr>02.09</sdr>|
|Lecture 9|Understanding Experimental Data <sdr>02.10</sdr>|
|Lecture 10|Understanding Experimental Data (cont.) <sdr>02.12</sdr>|
|Lecture 11|Introduction to Machine Learning <sdr>02.13</sdr>|
|Lecture 12|Clustering <sdr>02.14</sdr>|
|Lecture 13|Classification <sdr>02.15</sdr>|
|Lecture 14|Classification and Statistical Sins <sdr>02.16</sdr>|
|Lecture 15|Statistical Sins and Wrap Up <sdr>02.17</sdr>|


3 (2.2)

|Title|The Film Experience|
|:-|:-|
|**No.**|**MIT 21L011, Fall 2013**|
|**Date**|**2021.01.30 ~ 2021.03.17 （30 lectures）**|
|||
|Lecture 1|Introduction to MIT 21L011 <sdr>01.30</sdr>|
|Lecture 2|Keaton <sdr>01.31</sdr>|
|Lecture 3|Chaplin, Part I <sdr>02.02</sdr>|
|Lecture 4|Chaplin, Part II <sdr>02.04</sdr>|
|Lecture 5|Film as Global & Cultural Form; Montage, Mise en Sciene <sdr>02.06</sdr>|
|Lecture 6|German Film, Murnau <sdr>02.07</sdr>|
|Lecture 7|The Studio Era <sdr>02.08</sdr>|
|Lecture 8|The Work of Movies; Capra & Hawks <sdr>02.12</sdr>|
|Lecture 9|Alfred Hitchcock <sdr>02.13</sdr>|
|Lecture 10|Shadow of a Doubt, Reat Window <sdr>02.14</sdr>|
|Lecture 11|The Musical <sdr>02.15</sdr>|
|Lecture 12|The Musical (continued) <sdr>02.19</sdr>|
|Lecture 13|The Western <sdr>02.20</sdr>|
|Lecture 14|The Western (continued) <sdr>02.22</sdr>|
|Lecture 15|American Film in the 1970s, Part I <sdr>02.25</sdr>|
|Lecture 16|American Film in the 1970s, Part II <sdr>02.26</sdr>|
|Lecture 17|Renoir and Poetic Realism <sdr>02.28</sdr>|
|Lecture 18|Renoir's Grand Illusion <sdr>03.02</sdr>|
|Lecture 19|Italian Neorealism, Part I <sdr>03.03</sdr>|
|Lecture 20|Italian Neorealism, Part II <sdr>03.04</sdr>|
|Lecture 21|Truffaut, the Nouvelle Vague, The 400 Blows <sdr>03.05</sdr>|
|Lecture 22|Kurosawa and Rashomon <sdr>03.05</sdr>|
|Lecture 23|Summary Perspectives - Film as Art and Artifact <sdr>03.06</sdr>|
|Record|Meet the Educator <sdr>03.07</sdr>|
|Record|Why Study Film? <sdr>03.07</sdr>|
|Record|Approach to Lecturing <sdr>03.07</sdr>|
|Record|The Film Experience: A Course in Transition <sdr>03.07</sdr>|
|Record|The Video Lecture Conundrum <sdr>03.07</sdr>|
|Record|Beyond Film: Television & Literature <sdr>03.07</sdr>|
|Record|Thematic Spines of the Course <sdr>03.07</sdr>|

4 (2.2.2)

|Title|Music and Technology|
|:-|:-|
|**No.**|**21M.380, Fall 2009**|
|**Date**|**2021.02.20 ~ 2021.02.26 （4 lectures）**|
|||
|Lecture 13|Contemporary History and Aesthetics <sdr>02.21</sdr>|
|Lecture 12d|Contemporary History and Aesthetics <sdr>02.23</sdr>|
|Lecture 12w|Contemporary History and Aesthetics <sdr>02.23</sdr>|
|Lecture 16|Contemporary History and Aesthetics <sdr>02.24</sdr>|

5 (5.1)

|Title|Introduction to Psychology|
|:-|:-|
|**No.**|**MIT 9.00SC, Fall 2011**|
|**Date**|**2021.03.08 ~ 2021.04.13 （24 lectures）**|
|||
|Lecture 1|Introduction to Psychology <sdr>03.08</sdr>|
|Lecture 2|Introduction to Psychology <sdr>03.09</sdr>|
|Lecture 3|Introduction to Psychology <sdr>03.10</sdr>|
|Lecture 4|Introduction to Psychology <sdr>03.11</sdr>|
|Lecture 5|Introduction to Psychology <sdr>03.12</sdr>|
|Lecture 6|Introduction to Psychology <sdr>03.14</sdr>|
|Lecture 7|Introduction to Psychology <sdr>03.14</sdr>|
|Lecture 8|Introduction to Psychology <sdr>03.16</sdr>|
|Lecture 9|Introduction to Psychology <sdr>03.18</sdr>|
|Lecture 10|Introduction to Psychology <sdr>03.25</sdr>|
|Lecture 11|Introduction to Psychology <sdr>03.28</sdr>|
|Lecture 12|Introduction to Psychology <sdr>03.30</sdr>|
|Lecture 13|Introduction to Psychology <sdr>04.05</sdr>|
|Lecture 14|Introduction to Psychology <sdr>04.12</sdr>|
|Lecture 15|Introduction to Psychology <sdr>04.18</sdr>|
|Lecture 16|Introduction to Psychology <sdr>04.25</sdr>|
|Lecture 17|Introduction to Psychology <sdr>04.29</sdr>|
|Lecture 18|Introduction to Psychology <sdr>05.06</sdr>|
|Lecture 19|Introduction to Psychology <sdr>--</sdr>|
|Lecture 20|Introduction to Psychology <sdr>05.16</sdr>|
|Lecture 21| <sdr></sdr>|
|Lecture 22| <sdr></sdr>|
|Lecture 23| <sdr></sdr>|
|Lecture 24| <sdr></sdr>|

6 (5.2)

|Title|Artificial Intelligence|
|:-|:-|
|**No.**|**MIT6.034, Fall 2010**|
|**Date**|**2021.03.12 ~ 2021.04.27 （30 lectures）**|
|||
|Lecture 1|Intruduction and Scope <sdr>03.12</sdr>|
|Lecture 2|Reasonging Goal Trees and Problem Solving <sdr>03.14</sdr>|
|Lecture 3|Based Expert Systems <sdr>03.20</sdr>|
|Lecture 4|Search: Depth-First, Hill Climbing, Bean <sdr>03.20</sdr>|
|Lecture 5|Search: Optional, Branch and Bound, A* <sdr>03.28</sdr>|
|Lecture 6|Search Games, Minimax, and Alpha-Beta <sdr>03.31</sdr>|
|Lecture 7|Constraints: Interpreting Line Drawings <sdr>04.07</sdr>|
|Lecture 8|Constraints: Search, Domain Reduction <sdr>04.13</sdr>|
|Lecture 9|Constraints: Vistual Object Recognition <sdr>04.18</sdr>|
|Lecture 10|Introduction to Learning, Nearest Neighbors <sdr>04.19</sdr>|
|Lecture 11|Learning: Identification Trees, Disorder <sdr>04.21</sdr>|
|Lecture 12a|Neural Nets <sdr>04.27</sdr>|
|Lecture 12b|Deep Neural Nets <sdr>05.03</sdr>|
|Lecture 13| <sdr></sdr>|
|Lecture 14| <sdr></sdr>|
|Lecture 15| <sdr></sdr>|
|Lecture 16| <sdr></sdr>|
|Lecture 17| <sdr></sdr>|
|Lecture 18| <sdr></sdr>|
|Lecture 19| <sdr></sdr>|
|Lecture 20| <sdr></sdr>|
|Lecture 21| <sdr></sdr>|
|Lecture 22| <sdr></sdr>|
|Lecture 23| <sdr></sdr>|
|Lecture 24| <sdr></sdr>|
|Lecture 25| <sdr></sdr>|
|Lecture 26| <sdr></sdr>|
|Lecture 27| <sdr></sdr>|
|Lecture 28| <sdr></sdr>|
|Lecture 29| <sdr></sdr>|
|Lecture 30| <sdr></sdr>|

7 (5.3)

|Title|Design and Analysis of Algorithms|
|:-|:-|
|**No.**|**MIT6.046J, Fall 2015**|
|**Date**|**2021.03.14 ~ 2021.05.03 （30 lectures）**|
|||
|Lecture 1|Clourse Overview, Interval Scheduling <sdr>03.14</sdr>|
|Lecture 2|Divide & Conquer: Convex Hull, Median Finding <sdr>03.15</sdr>|
|Lecture R1|Matrix Multiplication and the Master Theoren <sdr>03.15</sdr>|
|Lecture 3|Divide & Conquer: FFT <sdr>03.17</sdr>|
|Lecture R2|2-3 Trees and B-Trees <sdr>03.20</sdr>|
|Lecture 4|Divide & Conquer: van Emde Boas Trees <sdr>03.27</sdr>|
|Lecture 5|Amortization: Amortized Analysis <sdr>04.01</sdr>|
|Lecture 6|Randomization: Matrix Multiply, Quicksort <sdr>04.08</sdr>|
|Lecture 9| <sdr></sdr>|
|Lecture 10| <sdr></sdr>|
|Lecture 11| <sdr></sdr>|
|Lecture 12| <sdr></sdr>|
|Lecture 13| <sdr></sdr>|
|Lecture 14| <sdr></sdr>|
|Lecture 15| <sdr></sdr>|
|Lecture 16| <sdr></sdr>|
|Lecture 17| <sdr></sdr>|
|Lecture 18| <sdr></sdr>|
|Lecture 19| <sdr></sdr>|
|Lecture 20| <sdr></sdr>|
|Lecture 21| <sdr></sdr>|
|Lecture 22| <sdr></sdr>|
|Lecture 23| <sdr></sdr>|
|Lecture 24| <sdr></sdr>|
|Lecture 25| <sdr></sdr>|
|Lecture 26| <sdr></sdr>|
|Lecture 27| <sdr></sdr>|
|Lecture 28| <sdr></sdr>|
|Lecture 29| <sdr></sdr>|
|Lecture 30| <sdr></sdr>|
|Lecture 31| <sdr></sdr>|
|Lecture 32| <sdr></sdr>|
|Lecture 33| <sdr></sdr>|
|Lecture 34| <sdr></sdr>|

8 (5.4)

|Title|Mathematics for Computer Science|
|:-|:-|
|**No.**|**MIT6.042J, Spring 2015**|
|**Date**|**2021.03.16 ~ 2021.08.31 （111 lectures）**|
|||
|Lecture 1.1.1|Welcome to 6.042 <sdr>03.16</sdr>|
|Lecture 1.1.2|Intro to Proofs: Part 1 <sdr>03.15</sdr>|
|Lecture 1.1.3|Intro to Proofs: Part 2 <sdr>03.17</sdr>|
|Lecture 1.2.1|Proof by Contradiction <sdr>03.17</sdr>|
|Lecture 1.2.3|Proof by Cases <sdr>03.17</sdr>|
|Lecture 1.3.1|Well Ordering Principle 1 <sdr>03.17</sdr>|
|Lecture 1.3.3|Well Ordering Principle 2 <sdr>03.18</sdr>|
|Lecture 1.3.5|Well Ordering Principle 3 <sdr>--</sdr>|
|Lecture 1.4.1|Propositional Operators <sdr>03.19</sdr>|
|Lecture 1.4.3|Digital Logic <sdr>03.19</sdr>|
|Lecture 1.4.4|Truth Tables <sdr>--</sdr>|
|Lecture 1.5.1|Predicate Logic 1 <sdr>--</sdr>|
|Lecture 1.5.2|Predicate Logic 2 <sdr>03.25</sdr>|
|Lecture 1.5.4|Predicate Logic 3 <sdr>--</sdr>|
|Lecture 1.6.1|Sets Definitions <sdr>03.30</sdr>|
|Lecture 1.7.1|Relations <sdr>03.31</sdr>|
|Lecture 1.7.3|Relational Mappings <sdr>04.07</sdr>|
|Lecture 1.7.5|Finite Cardinality <sdr>04.07</sdr>|
|Lecture 1.8.1|Induction <sdr>04.10</sdr>|
|Lecture 1.8.2|Bogus Induction <sdr>04.12</sdr>|
|Lecture 1.8.4|Strong Induction <sdr>04.13</sdr>|
|Lecture 1.8.6|WOP vs Induction <sdr>04.15</sdr>|
|Lecture 1.9.1|State Machines Invariants <sdr>04.16</sdr>|
|Lecture 1.9.3|Derived Variables <sdr>04.17</sdr>|
|Lecture 1.10.1|Recursive Data <sdr>04.18</sdr>|
|Lecture 1.10.4|Structural Induction <sdr>04.19</sdr>|
|Lecture 1.10.7|Recursive Function <sdr>04.19</sdr>|
|Lecture 1.11.1|Cardinality <sdr>04.19</sdr>|
|Lecture 1.11.3|ountable Sets <sdr>04.21</sdr>|
|Lecture 1.11.4|Cantor's Theorem <sdr>04.24</sdr>|
|Lecture 1.11.7|The Halting Problem <sdr>04.25</sdr>|
|Lecture 1.11.9|Russell's Paradox <sdr>04.25</sdr>|
|Lecture 1.11.11|Set Theory Axioms <sdr>04.27</sdr>|
|Lecture 2.1.1|GCDs & Linear Combinations <sdr>04.27</sdr>|
|Lecture 2.1.2|Euclidean Algorithms <sdr>04.28</sdr>|
|Lecture 2.1.4|Pulverizer <sdr>04.29</sdr>|
|Lecture 2.1.6|Revisiting Die Hard <sdr>04.30</sdr>|
|Lecture 2.1.7|Prime Factorization <sdr>05.02</sdr>|
|Lecture 2.2.1|Congruence mod n <sdr>05.04</sdr>|
|Lecture 2.2.3|Inverses mod n <sdr>05.09</sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|

9 (6)

|Title|Introduction to Deep Learning|
|:-|:-|
|**No.**|**MIT6.S191**|
|**Date**|**2021.04.15 ~ 2021.06.31 （40 lectures）**|
|||
|Lecture 1|Introduction to Deep Learning <sdr>04.18</sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|
|Lecture | <sdr></sdr>|


### 试听后放弃的课程

<ol>
    <sd-time>2021</sd-time>
    <li>MIT 15.S12 Blockchain and Money, Fall 2018 <sd>01.24</sd></li>
    <li>MIT 3.091 Introduction to Solid-State Chemistry, Fall 2018 <sd>01.24</sd></li>
    <li>MIT MAS.S62 Cryptocurrency Engineering and Design, Spring 2018 <sd>03.08</sd></li>
</ol>

