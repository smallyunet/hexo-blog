<!DOCTYPE html><html lang="zh-cn"><head><title>对 Psyche Network 项目的分析（AI）</title><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta name="viewport" content="width=device-width, initial-scale=0.5"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="manifest" href="/site.webmanifest"><link rel="stylesheet" href="/css/highlight/xcode.min.css"><link rel="stylesheet" href="/css/bootstrap/bootstrap-tooltips.css"><link rel="stylesheet" href="/css/post.css"><script src="/js/jquery.min.js"></script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="smallyu的博客（疯狂版）" type="application/atom+xml">
</head><body><script>if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent)) {
  document.body.classList.add('mobile')
  var navbar = document.querySelector('nav.navbar');
  if (navbar) {
    navbar.classList.remove('navbar-fixed-top');
  }
}
</script><div><div class="inner"><h1>对 Psyche Network 项目的分析（AI）</h1><div class="time">2025-08-01</div><ul class="tags"><li><span>#</span><a href="/tags/项目分析/">项目分析</a></li></ul><h3 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h3><p><a href="https://psyche.network/runs">Psyche Network</a> 是 AI + Web3 赛道的一个项目，由 <a href="https://nousresearch.com/">Nous Research</a> 团队研发，两个月前获得了 Paradigm 机构 5 千万美元的 <a href="https://cointelegraph.com/news/nous-research-raises-50m-paradigm-decentralized-ai-solana">A 轮融资</a>。</p>
<p>Psyche Network 的项目背景在 <a href="https://nousresearch.com/nous-psyche/">官方说明文章</a> 里有详细介绍。Nous Research 团队研发出了一种去中心化的算法 DeMo，这种算法能够把大语言模型（LLM）的训练，放到分布式网络里进行，不需要集群服务那种高耦合。就类似比特币挖矿的矿池一样，会把大的计算任务，拆解为小的计算任务，分发给不同的 Client 节点进行计算，计算之后再把结果汇总起来。</p>
<p>当然 LLM 的训练和矿池的挖矿，从算法原理上完全是两码事，这里只是想类比说明便于理解。具体 DeMo 是怎么从算法角度把任务拆解和合并的，可以看 <a href="https://blog.lambdaclass.com/introducing-demo-decoupled-momentum-optimization-for-efficient-distributed-llm-training/">官方的解释</a>，反正我没看懂，就是一堆向量、权重、loss function 什么的术语。关于怎么防止节点提交虚假数据之类，我认为也都在算法的设计范畴，后续就不多讨论算法本身的有效性了。</p>
<p>DeMo 的 <a href="https://arxiv.org/pdf/2411.19870">论文</a> 里用了 100 billion 的 tokens 做训练测试，得到了比较好的结果。100 B tokens 是什么概念呢，比如 <a href="https://github.com/deepseek-ai/DeepSeek-V3?tab=readme-ov-file#4-evaluation-results">DeekSeek-V3</a> 的 tokens 数量是 15 TB，可见 DeMo 在实验阶段的 tokens 数量级，距离商用产品还差很多。可以对比一些其他模型的 tokens 数量：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>参数量</th>
<th>预训练 tokens 数量</th>
<th>公开来源或泄露信息</th>
</tr>
</thead>
<tbody><tr>
<td>GPT-3</td>
<td>175 B</td>
<td>≈ 499 B</td>
<td>论文及后续综述</td>
</tr>
<tr>
<td>GPT-3.5</td>
<td>175 B</td>
<td>推测 ~1 T 左右</td>
<td>—</td>
</tr>
<tr>
<td>GPT-4</td>
<td>1.7 T</td>
<td>≈ 13 T tokens</td>
<td>SemiAnalysis &#x2F; The Decoder 报告</td>
</tr>
<tr>
<td>Llama 3</td>
<td>70 B</td>
<td>&gt; 15 T tokens</td>
<td>Meta 官方模型卡</td>
</tr>
<tr>
<td>DeMo OLMo</td>
<td>1 B</td>
<td>0.1 T tokens（100 B）</td>
<td>DeMo 论文</td>
</tr>
</tbody></table>
<p>Psyche Network 基于 DeMo 的算法原理，结合区块链来构建分布式网络，第一阶段的目标是训练出 40 B parameters, 20 T tokens 的模型。关于 <code>parameters</code> 和 <code>tokens</code> 这两个指标，我的理解是，<code>parameters</code> 是训练一开始就定义好的固定指标，<code>tokens</code> 则是需要不断进行计算和训练的，而 DeMo 解决的是 <code>tokens</code> 的分布式计算。Psyche Network 官网上有实时显示当前的训练进度，目前已经达到了 1 TB 的 tokens 数量：</p>
<img src="1.png" width="80%">

<p>这个模型训练完，也许可以接近 GPT-3 的水平。对比来看虽然 tokens 数量比 GPT-3 多，但是 parameters 比 GPT-3 少，所以最终效果应该不如 GPT-3。</p>
<h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><p>Psyche Network 的 <a href="https://docs.psyche.network/explain/index.html">文档</a> 里有介绍整体的项目结构，比较好理解，有一个中心化的 Coordinator 负责创建训练任务，其余的 Client 负责接收任务、提交任务结果。在没有区块链的场景下，Coordinator 与 Client 之间的通信是通过直接的 TCP 连接完成的。而有了区块链之后，Coordinator 和 Client 之间就是通过区块链来传递消息了。</p>
<img src="2.png" width="40%">

<p>Psyche Network 的 <a href="https://github.com/PsycheFoundation/psyche/tree/main/architectures">代码仓库</a> 里同时保留了 <code>centralized</code> 和 <code>decentralized</code> 两个版本的代码架构，这其实不太是好事，因为说明这个项目原本可以中心化运行，只是现在在做一些去中心化改造。这样的项目去中心化程度肯定是有限的。</p>
<p>而所谓去中心化版本的部分，Psyche Network 选择了 Solana 来作为运行智能合约的区块链平台，这也许和 Psyche Network 原本的项目就是用 Rust 语言有关。</p>
<p>代码仓库的 decentralized 目录下，有一些 Solana 的合约代码，这些 Solana 合约承担起了创建训练任务、计算每个 Client 节点的奖励、分发奖励的功能。</p>
<p>Psyche Network 目前只是测试网阶段，链上交易也都是在 Solana 的 Devnet 上进行，可以直接看合约文件里的 <code>declare_id!()</code> 语句，里面写的就是合约地址，比如 coordinator 的合约地址是 <code>HR8RN2TP9E9zsi2kjhvPbirJWA1R6L6ruf4xNNGpjU5Y</code>，能在 <a href="https://solscan.io/account/HR8RN2TP9E9zsi2kjhvPbirJWA1R6L6ruf4xNNGpjU5Y?cluster=devnet">区块链浏览器</a> 上看到频繁的交易记录。</p>
<p>至于奖励的计算，因为有 Coordinator 这个中心化角色的存在，所以事情比较简单，Coordinator 在收到 Client 地任务结果后进行验证，如果没问题，则发起一笔链上交易，给 Client 记分。具体代码是 <a href="https://github.com/PsycheFoundation/psyche/blob/main/architectures/decentralized/solana-coordinator/programs/solana-coordinator/src/instance_state.rs#L146-L149">这两行</a>：</p>
<img src="3.png" width="80%">

<p>每个 Client 的分数都记录在合约里，Client 想领取奖励，就自己到 treasurer 合约上 claim，treasurer 会根据分数和汇率计算并转账代币。</p>
<p>那么 treasurer 分发的奖励是哪个代币呢？具体代币是 Coordinator 在创建任务的时候 <a href="https://github.com/PsycheFoundation/psyche/blob/main/architectures/decentralized/solana-treasurer/programs/solana-treasurer/src/logic/run_create.rs#L34">指定的</a>，只要是标准的 SPL 代币都可以。</p>
<img src="4.png" width="70%">

<p>所以整体来看，Psyche Network 是利用 Solana 区块链来记录任务 Meta 信息、计算任务奖励、分发奖励等。只要 Client 的加入是 permissonless 的，Psyche Network 就确实达到了和宣传一样的效果，让 LLM 模型训练的算力去中心化。</p>
<p>而代币的分发和奖励虽然是区块链项目的常规操作，但是至少附加了公开透明等特性，而且不出意外的话，Psyche Network 最终会走到发币的一步，到时候任务奖励可能全用 Psyche Network 自己的代币进行，或者演变为 LLM 训练的任务平台，任何第三方都可以创建任务和分发奖励之类，像 Eigne Layer 那样。</p>
</div></div></body><script src="/js/highlight.min.js"></script><script src="/js/main.js"></script><script src="/js/bootstrap/bootstrap.min.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-Y7C0CVX9PK"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-Y7C0CVX9PK');</script></html>